# GuÃ­a de Pruebas: BÃºsqueda Vectorial

## ðŸ“‹ Prerequisitos

1. âœ… **pgvector configurado** en Supabase (ejecutar `setup-pgvector.sql`)
2. âœ… **Variables de entorno configuradas:**
   - `SUPABASE_URL`
   - `SUPABASE_KEY`
   - `OPENAI_API_KEY`
3. âœ… **Dependencias instaladas:**
   ```bash
   pip install openai supabase python-dotenv
   ```

---

## ðŸš€ CÃ³mo Probar

### OpciÃ³n 1: Script de Prueba Completo

Ejecuta el script de prueba que prueba todas las funciones:

```bash
cd agents/candidate-evaluation
python test_vector_search.py
```

El script ejecutarÃ¡:
1. âœ… Generar embedding
2. âœ… Insertar chunk de prueba
3. âœ… Buscar chunks similares
4. âœ… Indexar candidato individual
5. âœ… Indexar JD Interview individual
6. âœ… Indexar todos los candidatos (opcional, limitado a 5)
7. âœ… Indexar todas las JD Interviews (opcional)
8. âœ… BÃºsqueda despuÃ©s de indexar
9. âœ… Limpieza de datos de prueba

### OpciÃ³n 2: Pruebas Individuales desde Python

Abre un shell de Python:

```bash
cd agents/candidate-evaluation
python
```

Luego ejecuta:

```python
from tools.vector_tools import (
    generate_embedding,
    search_similar_chunks,
    index_candidate,
    index_all_candidates
)

# 1. Probar generaciÃ³n de embedding
embedding = generate_embedding("Candidato con React y TypeScript")
print(f"Embedding generado: {len(embedding)} dimensiones")

# 2. Indexar un candidato
from tools.supabase_tools import get_candidates_data
import json

candidates = json.loads(get_candidates_data(limit=1))
if candidates:
    chunk_id = index_candidate(candidates[0])
    print(f"Candidato indexado: {chunk_id}")

# 3. Buscar candidatos similares
results = search_similar_chunks(
    query_text="Â¿QuÃ© candidatos tienen React?",
    match_threshold=0.6,
    match_count=5,
    entity_type_filter='candidate'
)

for result in results:
    print(f"Similitud: {result['similarity']:.3f}")
    print(f"Contenido: {result['content'][:100]}...")
    print()
```

---

## ðŸ“ Ejemplos de Pruebas

### Test 1: Generar Embedding

```python
from tools.vector_tools import generate_embedding

text = "Candidato con React y TypeScript"
embedding = generate_embedding(text)
print(f"Dimensiones: {len(embedding)}")  # Debe ser 1536
```

**Resultado esperado:**
```
âœ… Embedding generado exitosamente
   Dimensiones: 1536
```

### Test 2: Indexar Candidato

```python
from tools.vector_tools import index_candidate
from tools.supabase_tools import get_candidates_data
import json

# Obtener un candidato
candidates = json.loads(get_candidates_data(limit=1))
if candidates:
    chunk_id = index_candidate(candidates[0])
    print(f"Chunk ID: {chunk_id}")
```

**Resultado esperado:**
```
âœ… Candidato indexado exitosamente
   Chunk ID: uuid-del-chunk
```

### Test 3: Buscar Chunks Similares

```python
from tools.vector_tools import search_similar_chunks

results = search_similar_chunks(
    query_text="Â¿QuÃ© candidatos tienen React?",
    match_threshold=0.6,
    match_count=5,
    entity_type_filter='candidate'
)

for result in results:
    print(f"Similitud: {result['similarity']:.3f}")
    print(f"Contenido: {result['content']}")
```

**Resultado esperado:**
```
âœ… BÃºsqueda completada
   Resultados encontrados: X
   [Lista de chunks similares con sus similitudes]
```

### Test 4: Indexar Todos los Candidatos

```python
from tools.vector_tools import index_all_candidates

count = index_all_candidates(limit=10)  # Indexar solo 10 para prueba
print(f"Candidatos indexados: {count}")
```

**Resultado esperado:**
```
âœ… IndexaciÃ³n completada
   Candidatos indexados: 10
```

---

## ðŸ” Verificar en Supabase

### Ver chunks indexados

```sql
-- Ver todos los chunks
SELECT 
  id,
  entity_type,
  entity_id,
  LEFT(content, 100) as content_preview,
  created_at
FROM knowledge_chunks
ORDER BY created_at DESC
LIMIT 10;
```

### Ver estadÃ­sticas

```sql
-- EstadÃ­sticas por tipo de entidad
SELECT 
  entity_type,
  COUNT(*) as total_chunks
FROM knowledge_chunks
GROUP BY entity_type;
```

### Probar bÃºsqueda directamente

```sql
-- Nota: Necesitas un embedding real para probar esto
-- Esto es solo para referencia
SELECT * FROM search_similar_chunks(
  '[0.123, 0.456, ...]'::vector(1536),  -- embedding de prueba
  0.7,
  10,
  'candidate'
);
```

---

## ðŸ› Troubleshooting

### Error: "OpenAI no estÃ¡ disponible"

**Causa:** `OPENAI_API_KEY` no estÃ¡ configurado o OpenAI no estÃ¡ instalado.

**SoluciÃ³n:**
```bash
pip install openai
# Y asegÃºrate de tener OPENAI_API_KEY en tu .env
```

### Error: "SUPABASE_URL y SUPABASE_KEY deben estar configurados"

**Causa:** Variables de entorno no configuradas.

**SoluciÃ³n:**
Verifica que tu `.env` tenga:
```
SUPABASE_URL=tu_url
SUPABASE_KEY=tu_key
```

### Error: "function search_similar_chunks does not exist"

**Causa:** No se ejecutÃ³ el script `setup-pgvector.sql`.

**SoluciÃ³n:**
Ejecuta el script SQL completo en Supabase SQL Editor.

### Error: "relation knowledge_chunks does not exist"

**Causa:** La tabla no fue creada.

**SoluciÃ³n:**
Ejecuta el script `setup-pgvector.sql` en Supabase.

### No encuentra resultados en bÃºsqueda

**Posibles causas:**
1. No hay chunks indexados â†’ Indexa algunos datos primero
2. Threshold muy alto â†’ Baja el `match_threshold` a 0.5 o 0.6
3. Embeddings no coinciden â†’ Verifica que uses el mismo modelo

**SoluciÃ³n:**
```python
# Bajar threshold para testing
results = search_similar_chunks(
    query_text="tu pregunta",
    match_threshold=0.5,  # MÃ¡s permisivo
    match_count=10
)
```

---

## ðŸ“Š Verificar que Funciona

### Checklist de VerificaciÃ³n

1. âœ… **Embedding se genera:**
   ```python
   embedding = generate_embedding("test")
   assert len(embedding) == 1536
   ```

2. âœ… **Chunk se inserta:**
   ```python
   chunk_id = insert_knowledge_chunk(...)
   assert chunk_id is not None
   ```

3. âœ… **BÃºsqueda encuentra resultados:**
   ```python
   results = search_similar_chunks("React", match_threshold=0.5)
   assert len(results) > 0
   ```

4. âœ… **Candidatos se indexan:**
   ```python
   count = index_all_candidates(limit=1)
   assert count > 0
   ```

---

## ðŸŽ¯ PrÃ³ximos Pasos DespuÃ©s de Probar

Una vez que las pruebas pasen:

1. âœ… **Indexar datos iniciales:**
   ```python
   # Indexar todos los candidatos
   index_all_candidates()
   
   # Indexar todas las JD Interviews
   index_all_jd_interviews()
   ```

2. âœ… **Integrar en el chatbot:**
   - Usar `search_similar_chunks` en el endpoint del chatbot
   - Combinar resultados con SQL queries
   - Generar respuestas con contexto

3. âœ… **IndexaciÃ³n incremental:**
   - Indexar cuando se crea un candidato
   - Actualizar cuando se modifica
   - Eliminar cuando se borra

---

## ðŸ’¡ Tips

- **Threshold recomendado:** 0.7 para producciÃ³n, 0.5-0.6 para testing
- **Match count:** 10-15 chunks es suficiente para contexto
- **Indexar incrementalmente:** Mejor que indexar todo de una vez
- **Verificar embeddings:** AsegÃºrate de usar el mismo modelo siempre

---

## ðŸ“š Referencias

- Ver `PGVECTOR_SETUP.md` para configuraciÃ³n
- Ver `vector_tools.py` para cÃ³digo fuente
- Ver `test_vector_search.py` para ejemplos completos
